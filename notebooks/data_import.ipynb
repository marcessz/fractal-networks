{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import os\n",
    "import networkx as nx\n",
    "import generators\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_import(directory):\n",
    "    paths=glob(os.path.join(directory,'*'))\n",
    "    dir_names=os.listdir(directory)\n",
    "    \n",
    "    dict_of_graphs = collections.defaultdict(list)\n",
    "    \n",
    "    if dir_names[0] == \".ipynb_checkpoints\":\n",
    "        dir_names.pop(0)\n",
    "    \n",
    "    for i, graph_dir in enumerate(paths):\n",
    "        paths_graphs = glob(os.path.join(graph_dir,'*'))\n",
    "        \n",
    "        for j, edgelist in enumerate(paths_graphs):\n",
    "            graph = nx.read_edgelist(edgelist)\n",
    "            dict_of_graphs[dir_names[i]].append(graph)\n",
    "    \n",
    "    return dict_of_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfm_graphs = graph_import(\"./model_graphs/rbfm\")\n",
    "mixture_graphs = graph_import(\"./model_graphs/mixture\")\n",
    "shm_graphs = graph_import(\"./model_graphs/shm\")\n",
    "uv_graphs = graph_import(\"./model_graphs/uvflower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_f(g):\n",
    "        \n",
    "    if nx.is_connected(g):\n",
    "        largest_comp = g\n",
    "    else:\n",
    "        cc = sorted(nx.connected_components(g), key=len, reverse=True)\n",
    "        largest_comp = g.subgraph(cc[0]).copy()\n",
    "            \n",
    "    if nx.number_of_selfloops(largest_comp)>0: \n",
    "        largest_comp.remove_edges_from(list(nx.selfloop_edges(largest_comp)))\n",
    "        \n",
    "    return nx.convert_node_labels_to_integers(largest_comp)\n",
    "\n",
    "\n",
    "def network_import_nx(directory):\n",
    "    paths=glob(os.path.join(directory,'*'))\n",
    "    file_names=os.listdir(directory)\n",
    "#     print(len(paths))\n",
    "#     print(len(file_names))\n",
    "    graphs_and_names=[]\n",
    "    \n",
    "    if file_names[0] == \".ipynb_checkpoints\":\n",
    "        file_names.pop(0)\n",
    "    \n",
    "    for index,file in enumerate(paths):\n",
    "        edge_data=open(file,'r', encoding = \"ISO-8859-1\")\n",
    "        edge_lines=edge_data.readlines()\n",
    "        edge_data.close()\n",
    "        if '.inp' not in file_names[index]:\n",
    "            edge_list=[' '.join(str.split(lines)[0:2]) for lines in edge_lines]\n",
    "        else:\n",
    "            print('inp')\n",
    "            edge_list=[' '.join(str.split(lines)[1:3]) for lines in edge_lines]\n",
    "#             print(edge_list)\n",
    "        graphs_and_names += [(file_names[index], aux_f(nx.convert_node_labels_to_integers(nx.parse_edgelist(edge_list, comments='%'))))]\n",
    "    return(graphs_and_names)\n",
    "\n",
    "\n",
    "def network_import_nx_metabolic(directory):\n",
    "    paths=glob(os.path.join(directory,'*'))\n",
    "    file_names=os.listdir(directory)\n",
    "    graphs_and_names=[]\n",
    "    \n",
    "    if file_names[0] == \".ipynb_checkpoints\":\n",
    "        file_names.pop(0)\n",
    "    \n",
    "    for index,file in enumerate(paths):\n",
    "        edge_data=open(file,'r')\n",
    "        edge_lines=edge_data.readlines()\n",
    "        edge_data.close()\n",
    "        if '_tab' not in file_names[index]:\n",
    "            edge_list=[' '.join(lines.split()[0:2]) for lines in edge_lines]\n",
    "        else:\n",
    "            edge_list=[' '.join(lines.strip(\"\\n\").split(\"\\t\")[0:2]) for lines in edge_lines]\n",
    "\n",
    "        graphs_and_names += [(file_names[index], aux_f(nx.convert_node_labels_to_integers(nx.parse_edgelist(edge_list, comments='%'))))]\n",
    "    return(graphs_and_names)\n",
    "\n",
    "\n",
    "def network_matrix_import(directory):\n",
    "    def g_from_sh(matrix_list_of_list):\n",
    "        m=np.array(matrix_list_of_list)\n",
    "        dim=list(m.shape)\n",
    "        edges=[]\n",
    "        index_of_horizontal_nodes=list(range(dim[0],np.sum(dim)))\n",
    "        for i in range(dim[0]):\n",
    "            for j in range(dim[1]):\n",
    "                if m[i][j] > 0:\n",
    "                    edges +=[(i,index_of_horizontal_nodes[j])]\n",
    "        g=nx.Graph()  \n",
    "        g.add_edges_from(edges)\n",
    "        return(g)\n",
    "\n",
    "    paths=glob(os.path.join(directory,'*.*'))\n",
    "    file_names=os.listdir(directory)\n",
    "    graphs_and_names=[]\n",
    "    \n",
    "    if file_names[0] == \".ipynb_checkpoints\":\n",
    "        file_names.pop(0)\n",
    "    \n",
    "    for index,file in enumerate(paths):\n",
    "        matrix_data=open(file,'r')\n",
    "        matrix_lines=matrix_data.readlines()\n",
    "        matrix_data.close()\n",
    "        matrix=[str.split(lines) for lines in matrix_lines]\n",
    "        array=np.array(matrix).astype(np.float)\n",
    "        graphs_and_names += [(file_names[index], aux_f(g_from_sh(array)))]\n",
    "    return(graphs_and_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp\n"
     ]
    }
   ],
   "source": [
    "graphs_real = network_import_nx('./Cheminformatics')\n",
    "graphs_real+=network_import_nx_metabolic(\"./metabolic\")\n",
    "graphs_real+=network_import_nx(\"./Brain\")\n",
    "graphs_real+=network_import_nx(\"./infrastructural\")\n",
    "graphs_real+=network_import_nx(\"./foodweb/edgelist\")\n",
    "graphs_real+=network_matrix_import(\"./foodweb/adj\")\n",
    "graphs_real+=network_import_nx(\"./social\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ezek még hasznosak lehetnek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Csúcsszámokat számolják ki a paraméterekből\n",
    "def num_of_nodes_rbfm(n, m):\n",
    "    if m==1:\n",
    "        return 2+(3**n - 1)\n",
    "    else:\n",
    "        return 2+((m/(m+1))*((2*m + 3)**n - 1))\n",
    "\n",
    "def num_of_nodes_shm(n, m):\n",
    "    return 2+((2*m + 1)**n - 1)\n",
    "\n",
    "def num_of_nodes_uv(u, v, n):\n",
    "    w = u+v\n",
    "    V=(w**n)*((w-2)/(w-1))+(w/(w-1))\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfm = pd.read_excel(\"final_database/rbfm_final.xlsx\")\n",
    "rbfm = rbfm.drop(rbfm.columns[0], axis=1)\n",
    "rbfm[\"V\"] = rbfm.apply(lambda x: num_of_nodes_rbfm(x['param1'], x['param2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = pd.read_excel(\"final_database/mixture_final.xlsx\")\n",
    "mixture = mixture.drop(mixture.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shm = pd.read_excel(\"final_database/shm_final.xlsx\")\n",
    "shm = shm.drop(shm.columns[0], axis=1)\n",
    "shm[\"V\"] = shm.apply(lambda x: num_of_nodes_shm(x['param1'], x['param2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv = pd.read_excel(\"final_database/uvflower_final.xlsx\")\n",
    "uv = uv.drop(uv.columns[0], axis=1)\n",
    "uv[\"V\"] = uv.apply(lambda x: num_of_nodes_uv(x['param1'], x['param2'], x['param3']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.read_excel(\"final_database/real_final.xlsx\")\n",
    "real = real.drop(real.columns[0], axis=1)\n",
    "real['fractality'] = np.where(real['R']>0.65, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
